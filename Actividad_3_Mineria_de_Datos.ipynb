{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Actividad 3 - Mineria de Datos.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkzFBYdqBa7S"
      },
      "source": [
        "# REGLAS DE ASOCIACION | ALGORITMO APRIORI\n",
        "> Autor: Elizon Frank Carcausto Mamani\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt2qpnaliy73"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools as iter\n",
        "from itertools import groupby, chain, combinations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RzUnHRIDT7m"
      },
      "source": [
        "## Generacion de ítemsets frecuentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDeG1kb4MuMv"
      },
      "source": [
        "Esta funcion toma las playlist en formato de lista de listas y encuentra los conjuntos frecuentes en base al min_support."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbzpkNRHniSg"
      },
      "source": [
        "def get_frequent_itemsets(list_playlists, min_support):\n",
        "  # Eliminarmos las canciones que se repiten en una las playlist\n",
        "  list_playlists = [list(set(e)) for e in list_playlists]\n",
        "  n = len(list_playlists)\n",
        "  print(n)\n",
        "\n",
        "  # Identificar los 1-items y contar sus indicencias en las transacciones\n",
        "  list_all_playlists = list(iter.chain(*list_playlists))\n",
        "  one_item = [(e, len(list(d))/n) for e, d in groupby(sorted(list_all_playlists))] # identificamos los n_items y contamos sus instancias \n",
        "  frec_one_item = [(e,s) for e,s in one_item if s >= min_support] # filtrar los items que son mayores o iguales al min_sopport\n",
        "  # frec_one_item es una lista de tuplas que cumple ('1-item', support)\n",
        "\n",
        "  # convertir a dataframe (por la gran cantidad de datos)\n",
        "  df_playlists = pd.DataFrame(frec_one_item)\n",
        "  df_playlists = df_playlists.rename(columns = {0:'items', 1:'support'})\n",
        "  print('1_items: ', len(one_item))\n",
        "  print(len(df_playlists),'\\n' )\n",
        "\n",
        "  # Encontramos los n_items frecuentes\n",
        "  k = 2\n",
        "  final = [] # conjunto final (lista de dataframe)\n",
        "  df_set_frec = df_playlists\n",
        "  # Empezamos el bucle desde 2_items\n",
        "  while len(df_set_frec) > 1:\n",
        "    n_items = merge_items(list(df_set_frec['items']), k)  # mesclamos los (n-1)_items para hallar los n_items\n",
        "    print(str(k) + '_items: ', len(n_items))\n",
        "    df_n_items = pd.DataFrame()\n",
        "    df_n_items['items'] = n_items\n",
        "    df_n_items['count'] = df_n_items['items'].apply(count_item, list_playlists = list_playlists) # contamos las instancias del n_item en las transacciones\n",
        "    df_n_items['support'] = df_n_items['count']/n # Hallamos el soporte de cada n_item\n",
        "    df_set_frec = df_n_items[df_n_items['support'] >= min_s] # filtramos los n_items con soporte mayor o igual al min_support\n",
        "    print(len(df_set_frec),'\\n')\n",
        "    k += 1\n",
        "    final.append(df_set_frec) \n",
        "  return pd.concat([final[i] for i in range(len(final))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prxaY2bsStx8"
      },
      "source": [
        "Esta funcion nos ayuda a contar las instancias de un n_item en el conjunto de transacciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeorwVIBpsHD"
      },
      "source": [
        "# la logica de la funcion es, que filtremos los elementos en la que el \n",
        "# n_item se encuentra para luego solo retornar la longitud de la lista\n",
        "def count_item(k_subset, list_playlists):\n",
        "  if type(k_subset) is str:\n",
        "    k_subset = [k_subset]\n",
        "  count_inst = lambda seq: set(k_subset).issubset(set(seq)) # subfuncion verifica si un n_item esta entre las transacciones\n",
        "  return len(list(filter(count_inst, list_playlists))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKY-na_xTE_I"
      },
      "source": [
        "Esta funcion simplifica la tarea de mesclar los (n-1)items para hallar los n-items\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdKeWpCjS2bK"
      },
      "source": [
        "def merge_items(elem, n):\n",
        "  if type(elem[0]) == str and n == 2:\n",
        "    return sorted(list(combinations(elem, n))) # mesclar los 1-items\n",
        "  else: # mesclar n-items\n",
        "    tmp = list(combinations(elem, 2)) # combinamos todos los n_items en grupos de 2\n",
        "    tmp2 = [tuple(set(iter.chain(*e))) for e in tmp if len(set(iter.chain(*e))) == n and e[0][0] == e[1][0]]  # filtramos los que tengan la longitd n\n",
        "    items = []\n",
        "    for e in tmp2:\n",
        "      if e not in items:\n",
        "        items.append(tuple(sorted(e))) # verificamos que los n-items no se repitan\n",
        "    return items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlN_43XuEC3w"
      },
      "source": [
        "## Generacion de reglas de asociacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySbxup8wVTdn"
      },
      "source": [
        "Esta funcion genera las reglas de asociacion en base a un umbral de confiancia y un lift."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT6MJ2VCz3p5"
      },
      "source": [
        "# La funcion recibe un dataframe de n_items mas frecuentes y la lista de transacciones\n",
        "def generate_association_rules(frequent_itemsets, transactions ,confidence = 0, lift = 0):\n",
        "  # Encontramos todas las posibles reglas en base al conjunto frecuente\n",
        "  list_rules = []\n",
        "  for i, row in frequent_itemsets.iterrows():\n",
        "    df_tmp = pd.DataFrame()\n",
        "    rules_tmp = rules(row['items'])\n",
        "    df_tmp['izq'] = [e[0] for e in rules_tmp]\n",
        "    df_tmp['der'] = [e[1] for e in rules_tmp]\n",
        "    df_tmp['count'] = [row['count']] * len(rules_tmp)\n",
        "    list_rules.append(df_tmp)\n",
        "  df_rules = pd.concat([e for e in list_rules])\n",
        "\n",
        "  # Hallamos los indicen de confianza y lift\n",
        "  df_rules['count der'] = df_rules['der'].apply(count_item, list_playlists = transactions)\n",
        "  df_rules['confidence'] = df_rules['count']/df_rules['count der']\n",
        "  df_rules['support'] = df_rules['count']/len(transactions)\n",
        "  df_rules['support der'] = df_rules['count der'] / len(transactions)\n",
        "  df_rules['lift'] = df_rules['confidence'] / df_rules['support der']\n",
        "\n",
        "  # filtramos las reglas que cumplan con los umbrales de confidence y lift\n",
        "  df_rules_f_tmp = df_rules[df_rules['confidence'] >= confidence]\n",
        "  df_rules_final = df_rules_f_tmp[df_rules_f_tmp['lift'] >= lift]\n",
        "  return df_rules_final.drop(['count', 'count der', 'support der'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQsDLfkBWsCy"
      },
      "source": [
        "Esta funcion genera todas las reglas posibles en base a un n-item."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG7OxXY7VJHy"
      },
      "source": [
        "def rules(item):\n",
        "  if len(item) == 2:\n",
        "    return [(item[0], item[1]), (item[1], item[0])] # reglas en base a 2-item\n",
        "  else:\n",
        "    tmp = []\n",
        "    comple = lambda e, conj: tuple(set(conj) - set(e)) # funcion que halla el complemento de un subconjunto\n",
        "    for i in range(len(item)-1, 0,-1):\n",
        "      # filtrsmos la reglas que no se repitan\n",
        "      tmp += [(e, comple(e, item)) for e in list(combinations(item, i)) if comple(e, item) not in tmp]\n",
        "    return tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaElNbYJFuRH"
      },
      "source": [
        "## Aplicado al dataset spotify.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bs94tYTxIj9"
      },
      "source": [
        "Preparando los datos de spotify.npy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkbe42PrX0iD"
      },
      "source": [
        "playlists = np.load('spotify.npy', allow_pickle=True)\n",
        "# convertir en una lista de listas\n",
        "list_playlists = list(playlists.tolist().values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7PP4LECxipe"
      },
      "source": [
        "Preparar los parametros: transacciones y  min_support."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rNSoinJD-od"
      },
      "source": [
        "trans = list_playlists\n",
        "min_s = 0.016 # min_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQqlGKICxyVk"
      },
      "source": [
        "Generar el conjunto de n-items frecuentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ev6FiHlXXl1"
      },
      "source": [
        "set_f = get_frequent_itemsets(trans, min_s)\n",
        "len(set_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pTIy0sJx-tt"
      },
      "source": [
        "Generar las reglas de asociasion "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjsBMf-0nFwl"
      },
      "source": [
        "rules = generate_association_rules(set_f, trans, confidence=0.5, lift=1.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KXUmEP12lkg"
      },
      "source": [
        "rules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJZtuvZVzUdt"
      },
      "source": [
        "## Presentacion de las 10 mejores reglas de asociacion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGbeokgbzUDG"
      },
      "source": [
        "rules_sort = rules.sort_values('confidence', ascending=False)\n",
        "k = 1\n",
        "for _, row in rules_sort.iterrows():\n",
        "  print('Nro:', k)\n",
        "  print('Regla: ', row['izq'] + ' ==> ' + row['der'])\n",
        "  print('Soporte: ' , row['support'])\n",
        "  print('Confianza: ', row['confidence'])\n",
        "  print('Sustento: ', row['lift'])\n",
        "  print('='*30)\n",
        "  k += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb58aIVW6n8u"
      },
      "source": [
        "## Comentar 4 reglas de asociacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBYB-t9d3JZ8"
      },
      "source": [
        "> ### Regla 1: HUMBLE. ==> DNA,  Soporte:  0.019,  Confianza:  0.8225, Sustento:  35.6065"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoCuRfIy4wnH"
      },
      "source": [
        "La regla numero 1 se aprecia que el soporte es alto lo que nos dice que con respecto a otras reglas esta es la de mayor fraccion en las transacciones. Tambien es la que mejor confianza posee y por la misma razon tambien es el que mejor puntuacion presenta en el sustento.\n",
        "\n",
        "Sin embargo ambos temas no comparten similitudes exactas de genero(Trap - pop), ritmo(bits energicos - bailable), o locatidad(Occidente - Oriente). La unica similitud que logre apreciar es que la tonalidad de los temas, ya que ambos destellan alegria. Esta es talvez una prueba de que hay cosas que los algoritmo pueden ver que nosotros no."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdWB2Uir4Ecs"
      },
      "source": [
        "> ### Regla 4: Bad and Boujee (feat. Lil Uzi Vert) ==> Bounce Back, Soporte:  0.0169, Confianza:  0.5690, Sustento:  19.1590"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm1F7dTL6mXV"
      },
      "source": [
        "Al realizar una busqueda de ambas cambiones se aprecia que ambas perteneces a un mismo genero y no solo eso sino que el estilo musical es muy pero muy similar, ambos acompañados de un bit tranquilo y con un trap que abordan la vida extravagante de un personaje. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU2FobQ539il"
      },
      "source": [
        "> ### Regla 8: XO TOUR Llif3 ==> Mask Off, Soporte: 0.0163, Confianza: 0.5158, Sustento:  16.3235"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEQudSwh8Xhf"
      },
      "source": [
        "Como en los anteriores ejemplos se aprecia que ambos temas perteneces a un mismo genero, el Trap, tambien ambos temas hablan sobre una vida caotica, tambien cave resaltar que junto a la regla 4 estos presentan indicadores bastante parecidos, y no solo eso si no que el genero y ritmo tambien son notablemente similares, diferenciando en la tonalidad el cual es mas positiva que la regla 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-045J5b3eh2"
      },
      "source": [
        "> ### Regla 10: Mask Off ==> XO TOUR Llif3, Soporte: 0.0163, Confianza: 0.5046, Sustento:  15.6236"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S2AqgFaAP9u"
      },
      "source": [
        "Pasa algo muy curioso con esta regla, ya que presentan los mismos temas que la Regla 8 solo que en orden inverso, tambien notamos que el indicador que mas difiere es el sustento. Una posible explicacion puede ser que el tema Mask off tuvo un alcance casi viral lo cual significaria que tiene un mayor soporte que el otro tema. Ya que el sustento de la Regla 10 esta fuertemente ligado al soporte del segundo tema, un tema menos viral que el primero."
      ]
    }
  ]
}